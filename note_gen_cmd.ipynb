{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc14e2cf-7b86-4071-b501-2ac1f3b63e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "import itertools\n",
    "import json\n",
    "import glob\n",
    "os.chdir('/fsx/wpq/github/metasummer2024/external/LLaVA') # jupyter lab moving ipynb does not change !pwd properly.\n",
    "import pandas as pd\n",
    "\n",
    "from rosemary.submit import shell_scripts_template, submit_job_slurm, multiline_to_singleline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b744a6d-dce1-48e8-92d4-b477d950802f",
   "metadata": {},
   "source": [
    "## Pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18cf9bdf-f6a9-4b1a-8bb0-6c814633c208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"args\": \"sbatch /fsx/wpq/.sbatch/2024-06-07_05:42:49_07b8b584-5dcb-42fa-a8e7-ca92e451dcca.sh\",\n",
      "        \"job_id\": 350166\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "nodes = 1; num_gpus = 8; cpu_mem = 1000; num_cpus = 96\n",
    "report_to = 'wandb'\n",
    "data_path = './data/liuhaotian/LLaVA-Pretrain/blip_laion_cc_sbu_558k.json'\n",
    "image_folder = './data/liuhaotian/LLaVA-Pretrain/images'\n",
    "train_size = None\n",
    "\n",
    "\n",
    "# ablate lm/vision/projector\n",
    "job_name = 'pt_1'\n",
    "model_name_or_path_list = [\n",
    "    './results/baselines/lmsys/vicuna-7b-v1.5',\n",
    "    # './results/baselines/NousResearch/Llama-2-7b-hf',\n",
    "    # './results/baselines/unsloth/llama-3-8b',\n",
    "]\n",
    "vision_tower_list = [\n",
    "    # './results/baselines/openai/clip-vit-large-patch14', # 224\n",
    "    './results/baselines/openai/clip-vit-large-patch14-336',\n",
    "]\n",
    "mm_projector_type_list = [\n",
    "    # 'linear',\n",
    "    'mlp2x_gelu',\n",
    "]\n",
    "\n",
    "\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "\n",
    "\n",
    "options_list = itertools.product(\n",
    "    model_name_or_path_list,\n",
    "    vision_tower_list,\n",
    "    mm_projector_type_list,\n",
    ")\n",
    "cmds = []\n",
    "\n",
    "for (\n",
    "    model_name_or_path,\n",
    "    vision_tower,\n",
    "    mm_projector_type,\n",
    ") in options_list:\n",
    "    output_dir  = f\"lm={os.path.basename(model_name_or_path)}\"\n",
    "    output_dir += f\"_vis={os.path.basename(vision_tower)}\"\n",
    "    output_dir += f\"_mm={mm_projector_type}\"\n",
    "    \n",
    "    output_dir = os.path.join('./results', job_name, output_dir)\n",
    "\n",
    "    os.environ['WANDB_NAME'] = output_dir.replace('./results/', '')\n",
    "    cmd = f\"\"\"\n",
    "    deepspeed llava/train/train_mem.py \\\n",
    "        --deepspeed ./scripts/zero2.json \\\n",
    "        --model_name_or_path {model_name_or_path} \\\n",
    "        --version plain \\\n",
    "        --data_path {data_path} \\\n",
    "        --image_folder {image_folder} \\\n",
    "        --vision_tower {vision_tower} \\\n",
    "        --mm_projector_type {mm_projector_type} \\\n",
    "        --tune_mm_mlp_adapter True \\\n",
    "        --mm_vision_select_layer -2 \\\n",
    "        --mm_use_im_start_end False \\\n",
    "        --mm_use_im_patch_token False \\\n",
    "        --bf16 True \\\n",
    "        {\"--train_size \" + str(train_size) if train_size else \"\"} \\\n",
    "        --num_train_epochs 1 \\\n",
    "        --per_device_train_batch_size 32 \\\n",
    "        --per_device_eval_batch_size 4 \\\n",
    "        --gradient_accumulation_steps 1 \\\n",
    "        --evaluation_strategy \"no\" \\\n",
    "        --save_strategy \"steps\" \\\n",
    "        --save_steps 24000 \\\n",
    "        --save_total_limit 1 \\\n",
    "        --learning_rate 1e-3 \\\n",
    "        --weight_decay 0. \\\n",
    "        --warmup_ratio 0.03 \\\n",
    "        --lr_scheduler_type \"cosine\" \\\n",
    "        --logging_steps 1 \\\n",
    "        --tf32 True \\\n",
    "        --model_max_length 2048 \\\n",
    "        --gradient_checkpointing True \\\n",
    "        --dataloader_num_workers 4 \\\n",
    "        --lazy_preprocess True \\\n",
    "        --report_to {'none' if test_run else report_to} \\\n",
    "        --output_dir {output_dir}\n",
    "    \"\"\"\n",
    "    \n",
    "    if test_run:\n",
    "        print('\\n'+' \\\\\\n\\t'.join([x.strip() for x in re.split(r'\\s{3,}', cmd)]))\n",
    "    \n",
    "    cmd = multiline_to_singleline(cmd)\n",
    "    cmds.append(cmd)\n",
    "    \n",
    "    \n",
    "    shell_scripts = shell_scripts_template.format(\n",
    "        profile='/fsx/wpq/.profile_local.sh',\n",
    "        conda_env='llava',\n",
    "        cwd=os.getcwd(),\n",
    "        cmd=cmd,\n",
    "        log_dir=os.getcwd(),\n",
    "        save_dir=output_dir\n",
    "    )\n",
    "    \n",
    "    out = submit_job_slurm(\n",
    "        shell_scripts,\n",
    "        job_name=job_name,\n",
    "        partition='learnai4p',\n",
    "        nodes=nodes,\n",
    "        num_cpus=num_cpus,\n",
    "        cpu_mem=cpu_mem,\n",
    "        num_gpus=num_gpus,\n",
    "        test_run=test_run,\n",
    "    )\n",
    "    \n",
    "    print(json.dumps(out, indent=4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3de604b-d5c5-4c98-a59e-47e92d5af478",
   "metadata": {},
   "source": [
    "## Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6bf710-f220-4f1c-8a9c-ce31cebecdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = 1; num_gpus = 8; cpu_mem = 1000; num_cpus = 96\n",
    "report_to = 'wandb'\n",
    "train_size = None # all data\n",
    "data_path = './data/liuhaotian/LLaVA-Instruct-150K/llava_v1_5_mix665k.json'\n",
    "image_folder = './data/'\n",
    "\n",
    "# model_name_or_path = './results/baselines/lmsys/vicuna-7b-v1.5'\n",
    "# pretrain_mm_mlp_adapter = './results/pretrain/llava-v1.5-7b/mm_projector.bin'\n",
    "# vision_tower = './results/baselines/openai/clip-vit-large-patch14-336'\n",
    "# mm_projector_type = 'mlp2x_gelu'\n",
    "\n",
    "# ablate lm/vision/projector\n",
    "job_name = 'sft_1'\n",
    "model_name_or_path_list = [\n",
    "    './results/baselines/lmsys/vicuna-7b-v1.5',\n",
    "    './results/baselines/NousResearch/Llama-2-7b-hf',\n",
    "]\n",
    "vision_tower_list = [\n",
    "    './results/baselines/openai/clip-vit-large-patch14', # 224\n",
    "    # './results/baselines/openai/clip-vit-large-patch14-336',\n",
    "]\n",
    "mm_projector_type_list = [\n",
    "    # 'linear',\n",
    "    'mlp2x_gelu',\n",
    "]\n",
    "\n",
    "\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "\n",
    "\n",
    "options_list = itertools.product(\n",
    "    model_name_or_path_list,\n",
    "    vision_tower_list,\n",
    "    mm_projector_type_list,\n",
    ")\n",
    "\n",
    "cmds = []\n",
    "\n",
    "\n",
    "for (\n",
    "    model_name_or_path,\n",
    "    vision_tower,\n",
    "    mm_projector_type,\n",
    ") in options_list:\n",
    "    output_dir  = f\"lm={os.path.basename(model_name_or_path)}\"\n",
    "    output_dir += f\"_vis={os.path.basename(vision_tower)}\"\n",
    "    output_dir += f\"_mm={mm_projector_type}\"\n",
    "    \n",
    "    output_dir = os.path.join('./results', job_name, output_dir)\n",
    "\n",
    "    mm_adaptor_job_dir = output_dir.replace(job_name, job_name.replace('sft', 'pt'))\n",
    "    pretrain_mm_mlp_adapter = os.path.join(mm_adaptor_job_dir, 'mm_projector.bin')\n",
    "    if not os.path.isfile(pretrain_mm_mlp_adapter):\n",
    "        raise ValueError(f'{pretrain_mm_mlp_adapter} does not exists.')\n",
    "\n",
    "    os.environ['WANDB_NAME'] = output_dir.replace('./results/', '')\n",
    "\n",
    "    cmd = f\"\"\"\n",
    "    deepspeed llava/train/train_mem.py \\\n",
    "        --deepspeed ./scripts/zero3.json \\\n",
    "        --model_name_or_path {model_name_or_path} \\\n",
    "        --version v1 \\\n",
    "        --data_path {data_path} \\\n",
    "        --image_folder {image_folder} \\\n",
    "        --vision_tower {vision_tower} \\\n",
    "        --pretrain_mm_mlp_adapter {pretrain_mm_mlp_adapter} \\\n",
    "        --mm_projector_type {mm_projector_type} \\\n",
    "        --mm_vision_select_layer -2 \\\n",
    "        --mm_use_im_start_end False \\\n",
    "        --mm_use_im_patch_token False \\\n",
    "        --image_aspect_ratio pad \\\n",
    "        --group_by_modality_length True \\\n",
    "        --bf16 True \\\n",
    "        {\"--train_size \" + str(train_size) if train_size else \"\"} \\\n",
    "        --num_train_epochs 1 \\\n",
    "        --per_device_train_batch_size 16 \\\n",
    "        --per_device_eval_batch_size 4 \\\n",
    "        --gradient_accumulation_steps 1 \\\n",
    "        --evaluation_strategy \"no\" \\\n",
    "        --save_strategy \"steps\" \\\n",
    "        --save_steps 50000 \\\n",
    "        --save_total_limit 1 \\\n",
    "        --learning_rate 2e-5 \\\n",
    "        --weight_decay 0. \\\n",
    "        --warmup_ratio 0.03 \\\n",
    "        --lr_scheduler_type \"cosine\" \\\n",
    "        --logging_steps 1 \\\n",
    "        --tf32 True \\\n",
    "        --model_max_length 2048 \\\n",
    "        --gradient_checkpointing True \\\n",
    "        --dataloader_num_workers 4 \\\n",
    "        --lazy_preprocess True \\\n",
    "        --report_to {'none' if test_run else report_to} \\\n",
    "        --output_dir {output_dir}\n",
    "    \"\"\"\n",
    "    \n",
    "    if test_run:\n",
    "        print('\\n'+' \\\\\\n\\t'.join([x.strip() for x in re.split(r'\\s{3,}', cmd)]))\n",
    "    \n",
    "    cmd = multiline_to_singleline(cmd)\n",
    "    cmds.append(cmd)\n",
    "    \n",
    "    \n",
    "    shell_scripts = shell_scripts_template.format(\n",
    "        profile='/fsx/wpq/.profile_local.sh',\n",
    "        conda_env='llava',\n",
    "        cwd=os.getcwd(),\n",
    "        cmd=cmd,\n",
    "        log_dir=os.getcwd(),\n",
    "        save_dir=output_dir\n",
    "    )\n",
    "    \n",
    "    out = submit_job_slurm(\n",
    "        shell_scripts,\n",
    "        job_name=job_name,\n",
    "        partition='learnai4p',\n",
    "        nodes=nodes,\n",
    "        num_cpus=num_cpus,\n",
    "        cpu_mem=cpu_mem,\n",
    "        num_gpus=num_gpus,\n",
    "        test_run=test_run,\n",
    "    )\n",
    "    \n",
    "    print(json.dumps(out, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1233839e-ca4d-4ec8-bf49-d2ccce11b9af",
   "metadata": {},
   "source": [
    "## Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "37d5f326-23b8-4754-9069-ceadc8360cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmds: #= 2\n",
      "[('mme', 'results/baselines/liuhaotian/llava-v1.5-7b'), ('mmbench', 'results/baselines/liuhaotian/llava-v1.5-7b')] \n",
      "\n",
      "\n",
      "{\n",
      "    \"args\": \"sbatch /fsx/wpq/.sbatch/2024-06-12_04:50:55_0ba05ecd-c5de-44da-af5e-cec93d3c20b0.sh\",\n",
      "    \"cmd\": \"bash scripts/v1_5/eval_mod/mme.sh results/baselines/liuhaotian/llava-v1.5-7b > results/baselines/liuhaotian/llava-v1.5-7b/eval/mme/mme.txt\"\n",
      "}\n",
      "{\n",
      "    \"args\": \"sbatch /fsx/wpq/.sbatch/2024-06-12_04:50:55_7e9ed27e-be46-42cb-b8b3-6b44b4542aec.sh\",\n",
      "    \"cmd\": \"bash scripts/v1_5/eval_mod/mmbench.sh results/baselines/liuhaotian/llava-v1.5-7b > results/baselines/liuhaotian/llava-v1.5-7b/eval/mmbench/mmbench.txt\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from rosemary.submit import submit_job_slurm\n",
    "nodes = 1; num_gpus = 8; cpu_mem = 1000; num_cpus = 96\n",
    "\n",
    "eval_script_dir = 'scripts/v1_5/eval_mod'\n",
    "eval_rest = True\n",
    "subdir_path_list = []\n",
    "subdir_filter_fn = lambda x: True\n",
    "\n",
    "subdir_path_list = [\n",
    "    'results/baselines/liuhaotian/llava-v1.5-7b',\n",
    "]\n",
    "\n",
    "task_names = [\n",
    "    'vqav2',\n",
    "    'gqa',\n",
    "    'vizwiz',\n",
    "    'textvqa',\n",
    "    'scienceqa',\n",
    "    'pope',\n",
    "    'mme',\n",
    "    'mmbench',\n",
    "]\n",
    "\n",
    "######\n",
    "\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "\n",
    "if len(subdir_path_list)==0:\n",
    "    subdir_path_list = []\n",
    "    for exp_dir in exp_dirs:\n",
    "        subdirs = list(os.listdir(exp_dir))\n",
    "        subdirs = filter(subdir_filter_fn, subdirs)\n",
    "        for subdir in subdirs:\n",
    "            subdir_path = os.path.join(exp_dir, subdir)\n",
    "            if not os.path.isfile(os.path.join(subdir_path, 'config.json')): # skip runs not yet finished\n",
    "                continue\n",
    "            subdir_path_list.append(subdir_path)\n",
    "\n",
    "@dataclass\n",
    "class TaskConfig:\n",
    "    task_finish_proof: str\n",
    "    num_gpus: int\n",
    "    bash_script_name: str\n",
    "\n",
    "task_configs = {\n",
    "    'vqav2': TaskConfig('*/answers_upload.json', 8, 'vqav2'),\n",
    "    'gqa': TaskConfig('*/*_predictions.json', 8, 'gqa'),\n",
    "    'vizwiz': TaskConfig('answers_upload.json', 1, 'vizwiz'),\n",
    "    'textvqa': TaskConfig('answers.jsonl', 1, 'textvqa'),\n",
    "    'scienceqa': TaskConfig('results.jsonl', 1, 'sqa'),\n",
    "    'pope': TaskConfig('answers.jsonl', 1, 'pope'),\n",
    "    'mme': TaskConfig('results', 1, 'mme'),\n",
    "    'mmbench': TaskConfig('*.xlsx', 1, 'mmbench'),\n",
    "}\n",
    "\n",
    "if eval_rest:\n",
    "    task_name_and_model = []\n",
    "    for subdir_path in subdir_path_list:\n",
    "        for task_name in task_names:\n",
    "            if not glob.glob(os.path.join(subdir_path, 'eval', task_name, task_configs[task_name].task_finish_proof)):\n",
    "                task_name_and_model.append((task_name, subdir_path))\n",
    "else:\n",
    "    task_name_and_model = list(itertools.product(task_names, subdir_path_list))\n",
    "    \n",
    "print('cmds: #=', len(list(task_name_and_model)))\n",
    "print(list(task_name_and_model), '\\n\\n')\n",
    "\n",
    "\n",
    "dfo = pd.DataFrame(task_name_and_model, columns=['task_name', 'model_name_or_path'])\n",
    "model_and_task_list = dfo.groupby('model_name_or_path')['task_name'].agg(list).to_dict()\n",
    "\n",
    "cmds = []\n",
    "for model_name_or_path, task_name_list in model_and_task_list.items():\n",
    "    model_name_or_path = model_name_or_path.rstrip('/')\n",
    "    for i, task_name in enumerate(task_name_list):\n",
    "        task_config = task_configs[task_name]\n",
    "        job_name = f'eval.{task_name}'\n",
    "        save_dir = f'{model_name_or_path}/eval/{task_name}'\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        if task_name.startswith(tuple(task_configs.keys())):\n",
    "            cmd = f\"bash {eval_script_dir}/{task_config.bash_script_name}.sh {model_name_or_path} > {os.path.join(save_dir, task_name+'.txt')}\"\n",
    "        else:\n",
    "            raise ValueError(f'{task_name} not supported.')\n",
    "\n",
    "        num_gpus = task_config.num_gpus            \n",
    "        cmd = multiline_to_singleline(cmd)\n",
    "        cmds.append(cmd)\n",
    "        \n",
    "        shell_scripts = shell_scripts_template.format(\n",
    "            profile='/fsx/wpq/.profile_local.sh',\n",
    "            conda_env='llava',\n",
    "            cwd=os.getcwd(),\n",
    "            cmd=cmd,\n",
    "            log_dir=os.getcwd(),\n",
    "            save_dir=save_dir\n",
    "        )\n",
    "        out = submit_job_slurm(\n",
    "            shell_scripts, \n",
    "            job_name=job_name,\n",
    "            partition='learnai4p',\n",
    "            nodes=nodes,\n",
    "            num_cpus=num_cpus,\n",
    "            cpu_mem=cpu_mem,\n",
    "            num_gpus=num_gpus,\n",
    "            test_run=test_run,\n",
    "        )\n",
    "        for x in out:\n",
    "            x.update({'cmd': cmd})\n",
    "\n",
    "        print(json.dumps(out[0], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "91711951-026d-4ce0-9a96-7dbbfe52c1d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (1375193315.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[45], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    CUDA_VISIBLE_DEVICES=0 bash scripts/v1_5/eval_mod/pope.sh results/baselines/liuhaotian/llava-v1.5-7b > results/baselines/liuhaotian/llava-v1.5-7b/eval/pope/pope.txt\u001b[0m\n\u001b[0m                                                                                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "\n",
    "CUDA_VISIBLE_DEVICES=1 bash scripts/v1_5/eval_mod/mme.sh results/baselines/liuhaotian/llava-v1.5-7b > results/baselines/liuhaotian/llava-v1.5-7b/eval/mme/mme.txt\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b02a1a9-0b8b-44af-a9e0-a0b98cabb9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "evalai challenge 2185 phase 4336 submit --file results/baselines/liuhaotian/llava-v1.5-7b/eval/vizwiz/answers_upload.json --large --private\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a655736f-3367-4cfa-b9fe-51f5f25e2a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/baselines/liuhaotian/llava-v1.5-7b/eval/vizwiz/answers_upload.json\n"
     ]
    }
   ],
   "source": [
    "!ls results/baselines/liuhaotian/llava-v1.5-7b/eval/vizwiz/answers_upload.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2366bfd3-f2c4-40e9-a252-7e69d8ea8138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>question</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>prediction</th>\n",
       "      <th>answer</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>241</td>\n",
       "      <td>Identify the question that Madelyn and Tucker'...</td>\n",
       "      <td>Does Madelyn's snowboard slide down a hill in ...</td>\n",
       "      <td>Does Madelyn's snowboard slide down a hill in ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>252</td>\n",
       "      <td>Which of the following could Laura and Isabell...</td>\n",
       "      <td>if the concrete from each batch took the same ...</td>\n",
       "      <td>if a new batch of concrete was firm enough to use</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>253</td>\n",
       "      <td>Which of the following was a dependent variabl...</td>\n",
       "      <td>the temperature of the soda</td>\n",
       "      <td>the size of the ice pieces</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A. the temperature of the soda</td>\n",
       "      <td>A</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>254</td>\n",
       "      <td>Which of the following was an independent vari...</td>\n",
       "      <td>the distance the footballs traveled</td>\n",
       "      <td>the air pressure in the footballs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>256</td>\n",
       "      <td>Which of the following could Devin's test show?</td>\n",
       "      <td>if the weather station would work when the tem...</td>\n",
       "      <td>how well the weather station would work when i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4372</th>\n",
       "      <td>3001982</td>\n",
       "      <td>In nature, what's the relationship between the...</td>\n",
       "      <td>Competitive relationships</td>\n",
       "      <td>Parasitic relationships</td>\n",
       "      <td>Symbiotic relationship</td>\n",
       "      <td>Predatory relationships</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4373</th>\n",
       "      <td>3001985</td>\n",
       "      <td>In nature, what's the relationship between the...</td>\n",
       "      <td>Competitive relationships</td>\n",
       "      <td>Parasitic relationships</td>\n",
       "      <td>Symbiotic relationship</td>\n",
       "      <td>Predatory relationships</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4374</th>\n",
       "      <td>3001986</td>\n",
       "      <td>In nature, what's the relationship between the...</td>\n",
       "      <td>Competitive relationships</td>\n",
       "      <td>Parasitic relationships</td>\n",
       "      <td>Symbiotic relationship</td>\n",
       "      <td>Predatory relationships</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4375</th>\n",
       "      <td>3001987</td>\n",
       "      <td>In nature, what's the relationship between the...</td>\n",
       "      <td>Competitive relationships</td>\n",
       "      <td>Parasitic relationships</td>\n",
       "      <td>Symbiotic relationship</td>\n",
       "      <td>Predatory relationships</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4376</th>\n",
       "      <td>3001988</td>\n",
       "      <td>In nature, what's the relationship between the...</td>\n",
       "      <td>Competitive relationships</td>\n",
       "      <td>Parasitic relationships</td>\n",
       "      <td>Symbiotic relationship</td>\n",
       "      <td>Predatory relationships</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4377 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index                                           question  \\\n",
       "0         241  Identify the question that Madelyn and Tucker'...   \n",
       "1         252  Which of the following could Laura and Isabell...   \n",
       "2         253  Which of the following was a dependent variabl...   \n",
       "3         254  Which of the following was an independent vari...   \n",
       "4         256    Which of the following could Devin's test show?   \n",
       "...       ...                                                ...   \n",
       "4372  3001982  In nature, what's the relationship between the...   \n",
       "4373  3001985  In nature, what's the relationship between the...   \n",
       "4374  3001986  In nature, what's the relationship between the...   \n",
       "4375  3001987  In nature, what's the relationship between the...   \n",
       "4376  3001988  In nature, what's the relationship between the...   \n",
       "\n",
       "                                                      A  \\\n",
       "0     Does Madelyn's snowboard slide down a hill in ...   \n",
       "1     if the concrete from each batch took the same ...   \n",
       "2                           the temperature of the soda   \n",
       "3                   the distance the footballs traveled   \n",
       "4     if the weather station would work when the tem...   \n",
       "...                                                 ...   \n",
       "4372                          Competitive relationships   \n",
       "4373                          Competitive relationships   \n",
       "4374                          Competitive relationships   \n",
       "4375                          Competitive relationships   \n",
       "4376                          Competitive relationships   \n",
       "\n",
       "                                                      B  \\\n",
       "0     Does Madelyn's snowboard slide down a hill in ...   \n",
       "1     if a new batch of concrete was firm enough to use   \n",
       "2                            the size of the ice pieces   \n",
       "3                     the air pressure in the footballs   \n",
       "4     how well the weather station would work when i...   \n",
       "...                                                 ...   \n",
       "4372                            Parasitic relationships   \n",
       "4373                            Parasitic relationships   \n",
       "4374                            Parasitic relationships   \n",
       "4375                            Parasitic relationships   \n",
       "4376                            Parasitic relationships   \n",
       "\n",
       "                           C                        D  \\\n",
       "0                        NaN                      NaN   \n",
       "1                        NaN                      NaN   \n",
       "2                        NaN                      NaN   \n",
       "3                        NaN                      NaN   \n",
       "4                        NaN                      NaN   \n",
       "...                      ...                      ...   \n",
       "4372  Symbiotic relationship  Predatory relationships   \n",
       "4373  Symbiotic relationship  Predatory relationships   \n",
       "4374  Symbiotic relationship  Predatory relationships   \n",
       "4375  Symbiotic relationship  Predatory relationships   \n",
       "4376  Symbiotic relationship  Predatory relationships   \n",
       "\n",
       "                          prediction answer split  \n",
       "0                                  B      B   dev  \n",
       "1                                  B      B   dev  \n",
       "2     A. the temperature of the soda      A   dev  \n",
       "3                                  B      B   dev  \n",
       "4                                  A      A   dev  \n",
       "...                              ...    ...   ...  \n",
       "4372                               C      D   dev  \n",
       "4373                               C      D   dev  \n",
       "4374                               D      D   dev  \n",
       "4375                               C      D   dev  \n",
       "4376                               C      D   dev  \n",
       "\n",
       "[4377 rows x 9 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = '/fsx/wpq/github/metasummer2024/external/LLaVA/results/baselines/liuhaotian/llava-v1.5-7b/eval/mmbench/mmbench_dev_20230712.xlsx'\n",
    "df = pd.read_excel(p, sheet_name=None)\n",
    "df['Sheet1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ea5e067b-b53d-4610-97bf-60b0ed9b2170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['answers',\n",
       " 'coco_pope_random.json',\n",
       " 'coco_pope_adversarial.json',\n",
       " 'coco',\n",
       " 'coco_pope_popular.json',\n",
       " 'llava_pope_test.jsonl']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceb146a-5113-4333-b5f0-617bed5c5965",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:llava]",
   "language": "python",
   "name": "conda-env-llava-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
