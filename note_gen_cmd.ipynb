{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc14e2cf-7b86-4071-b501-2ac1f3b63e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/fsx/wpq/miniconda3/envs/llava/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import re\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "import itertools\n",
    "import json\n",
    "import glob\n",
    "os.chdir('/fsx/wpq/github/metasummer2024/external/LLaVA') # jupyter lab moving ipynb does not change !pwd properly.\n",
    "import pandas as pd\n",
    "from rosemary.submit import shell_scripts_template, submit_job_slurm, multiline_to_singleline\n",
    "\n",
    "log_dir = '/fsx/wpq/.slurm_log'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b744a6d-dce1-48e8-92d4-b477d950802f",
   "metadata": {},
   "source": [
    "## Pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18cf9bdf-f6a9-4b1a-8bb0-6c814633c208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"args\": \"sbatch /fsx/wpq/.sbatch/2024-06-07_05:42:49_07b8b584-5dcb-42fa-a8e7-ca92e451dcca.sh\",\n",
      "        \"job_id\": 350166\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "nodes = 1; num_gpus = 8; cpu_mem = 1000; num_cpus = 96\n",
    "report_to = 'wandb'\n",
    "data_path = './data/liuhaotian/LLaVA-Pretrain/blip_laion_cc_sbu_558k.json'\n",
    "image_folder = './data/liuhaotian/LLaVA-Pretrain/images'\n",
    "train_size = None\n",
    "\n",
    "\n",
    "# ablate lm/vision/projector\n",
    "job_name = 'pt_1'\n",
    "model_name_or_path_list = [\n",
    "    './results/baselines/lmsys/vicuna-7b-v1.5',\n",
    "    # './results/baselines/NousResearch/Llama-2-7b-hf',\n",
    "    # './results/baselines/unsloth/llama-3-8b',\n",
    "]\n",
    "vision_tower_list = [\n",
    "    # './results/baselines/openai/clip-vit-large-patch14', # 224\n",
    "    './results/baselines/openai/clip-vit-large-patch14-336',\n",
    "]\n",
    "mm_projector_type_list = [\n",
    "    # 'linear',\n",
    "    'mlp2x_gelu',\n",
    "]\n",
    "\n",
    "\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "\n",
    "\n",
    "options_list = itertools.product(\n",
    "    model_name_or_path_list,\n",
    "    vision_tower_list,\n",
    "    mm_projector_type_list,\n",
    ")\n",
    "cmds = []\n",
    "\n",
    "for (\n",
    "    model_name_or_path,\n",
    "    vision_tower,\n",
    "    mm_projector_type,\n",
    ") in options_list:\n",
    "    output_dir  = f\"lm={os.path.basename(model_name_or_path)}\"\n",
    "    output_dir += f\"_vis={os.path.basename(vision_tower)}\"\n",
    "    output_dir += f\"_mm={mm_projector_type}\"\n",
    "    \n",
    "    output_dir = os.path.join('./results', job_name, output_dir)\n",
    "\n",
    "    os.environ['WANDB_NAME'] = output_dir.replace('./results/', '')\n",
    "    cmd = f\"\"\"\n",
    "    deepspeed llava/train/train_mem.py \\\n",
    "        --deepspeed ./scripts/zero2.json \\\n",
    "        --model_name_or_path {model_name_or_path} \\\n",
    "        --version plain \\\n",
    "        --data_path {data_path} \\\n",
    "        --image_folder {image_folder} \\\n",
    "        --vision_tower {vision_tower} \\\n",
    "        --mm_projector_type {mm_projector_type} \\\n",
    "        --tune_mm_mlp_adapter True \\\n",
    "        --mm_vision_select_layer -2 \\\n",
    "        --mm_use_im_start_end False \\\n",
    "        --mm_use_im_patch_token False \\\n",
    "        --bf16 True \\\n",
    "        {\"--train_size \" + str(train_size) if train_size else \"\"} \\\n",
    "        --num_train_epochs 1 \\\n",
    "        --per_device_train_batch_size 32 \\\n",
    "        --per_device_eval_batch_size 4 \\\n",
    "        --gradient_accumulation_steps 1 \\\n",
    "        --evaluation_strategy \"no\" \\\n",
    "        --save_strategy \"steps\" \\\n",
    "        --save_steps 24000 \\\n",
    "        --save_total_limit 1 \\\n",
    "        --learning_rate 1e-3 \\\n",
    "        --weight_decay 0. \\\n",
    "        --warmup_ratio 0.03 \\\n",
    "        --lr_scheduler_type \"cosine\" \\\n",
    "        --logging_steps 1 \\\n",
    "        --tf32 True \\\n",
    "        --model_max_length 2048 \\\n",
    "        --gradient_checkpointing True \\\n",
    "        --dataloader_num_workers 4 \\\n",
    "        --lazy_preprocess True \\\n",
    "        --report_to {'none' if test_run else report_to} \\\n",
    "        --output_dir {output_dir}\n",
    "    \"\"\"\n",
    "    \n",
    "    if test_run:\n",
    "        print('\\n'+' \\\\\\n\\t'.join([x.strip() for x in re.split(r'\\s{3,}', cmd)]))\n",
    "    \n",
    "    cmd = multiline_to_singleline(cmd)\n",
    "    cmds.append(cmd)\n",
    "    \n",
    "    \n",
    "    shell_scripts = shell_scripts_template.format(\n",
    "        profile='/fsx/wpq/.profile_local.sh',\n",
    "        conda_env='llava',\n",
    "        cwd=os.getcwd(),\n",
    "        cmd=cmd,\n",
    "        log_dir=log_dir,\n",
    "        save_dir=output_dir\n",
    "    )\n",
    "    \n",
    "    out = submit_job_slurm(\n",
    "        shell_scripts,\n",
    "        job_name=job_name,\n",
    "        partition='learnai4p',\n",
    "        nodes=nodes,\n",
    "        num_cpus=num_cpus,\n",
    "        cpu_mem=cpu_mem,\n",
    "        num_gpus=num_gpus,\n",
    "        log_path=os.path.join(log_dir, '%J.out'),\n",
    "        test_run=test_run,\n",
    "    )\n",
    "    \n",
    "    print(json.dumps(out, indent=4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3de604b-d5c5-4c98-a59e-47e92d5af478",
   "metadata": {},
   "source": [
    "## Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6bf710-f220-4f1c-8a9c-ce31cebecdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = 1; num_gpus = 8; cpu_mem = 1000; num_cpus = 96\n",
    "report_to = 'wandb'\n",
    "train_size = None # all data\n",
    "data_path = './data/liuhaotian/LLaVA-Instruct-150K/llava_v1_5_mix665k.json'\n",
    "image_folder = './data/'\n",
    "\n",
    "# model_name_or_path = './results/baselines/lmsys/vicuna-7b-v1.5'\n",
    "# pretrain_mm_mlp_adapter = './results/pretrain/llava-v1.5-7b/mm_projector.bin'\n",
    "# vision_tower = './results/baselines/openai/clip-vit-large-patch14-336'\n",
    "# mm_projector_type = 'mlp2x_gelu'\n",
    "\n",
    "# ablate lm/vision/projector\n",
    "job_name = 'sft_1'\n",
    "model_name_or_path_list = [\n",
    "    './results/baselines/lmsys/vicuna-7b-v1.5',\n",
    "    './results/baselines/NousResearch/Llama-2-7b-hf',\n",
    "]\n",
    "vision_tower_list = [\n",
    "    './results/baselines/openai/clip-vit-large-patch14', # 224\n",
    "    # './results/baselines/openai/clip-vit-large-patch14-336',\n",
    "]\n",
    "mm_projector_type_list = [\n",
    "    # 'linear',\n",
    "    'mlp2x_gelu',\n",
    "]\n",
    "\n",
    "\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "\n",
    "\n",
    "options_list = itertools.product(\n",
    "    model_name_or_path_list,\n",
    "    vision_tower_list,\n",
    "    mm_projector_type_list,\n",
    ")\n",
    "\n",
    "cmds = []\n",
    "\n",
    "\n",
    "for (\n",
    "    model_name_or_path,\n",
    "    vision_tower,\n",
    "    mm_projector_type,\n",
    ") in options_list:\n",
    "    output_dir  = f\"lm={os.path.basename(model_name_or_path)}\"\n",
    "    output_dir += f\"_vis={os.path.basename(vision_tower)}\"\n",
    "    output_dir += f\"_mm={mm_projector_type}\"\n",
    "    \n",
    "    output_dir = os.path.join('./results', job_name, output_dir)\n",
    "\n",
    "    mm_adaptor_job_dir = output_dir.replace(job_name, job_name.replace('sft', 'pt'))\n",
    "    pretrain_mm_mlp_adapter = os.path.join(mm_adaptor_job_dir, 'mm_projector.bin')\n",
    "    if not os.path.isfile(pretrain_mm_mlp_adapter):\n",
    "        raise ValueError(f'{pretrain_mm_mlp_adapter} does not exists.')\n",
    "\n",
    "    os.environ['WANDB_NAME'] = output_dir.replace('./results/', '')\n",
    "\n",
    "    cmd = f\"\"\"\n",
    "    deepspeed llava/train/train_mem.py \\\n",
    "        --deepspeed ./scripts/zero3.json \\\n",
    "        --model_name_or_path {model_name_or_path} \\\n",
    "        --version v1 \\\n",
    "        --data_path {data_path} \\\n",
    "        --image_folder {image_folder} \\\n",
    "        --vision_tower {vision_tower} \\\n",
    "        --pretrain_mm_mlp_adapter {pretrain_mm_mlp_adapter} \\\n",
    "        --mm_projector_type {mm_projector_type} \\\n",
    "        --mm_vision_select_layer -2 \\\n",
    "        --mm_use_im_start_end False \\\n",
    "        --mm_use_im_patch_token False \\\n",
    "        --image_aspect_ratio pad \\\n",
    "        --group_by_modality_length True \\\n",
    "        --bf16 True \\\n",
    "        {\"--train_size \" + str(train_size) if train_size else \"\"} \\\n",
    "        --num_train_epochs 1 \\\n",
    "        --per_device_train_batch_size 16 \\\n",
    "        --per_device_eval_batch_size 4 \\\n",
    "        --gradient_accumulation_steps 1 \\\n",
    "        --evaluation_strategy \"no\" \\\n",
    "        --save_strategy \"steps\" \\\n",
    "        --save_steps 50000 \\\n",
    "        --save_total_limit 1 \\\n",
    "        --learning_rate 2e-5 \\\n",
    "        --weight_decay 0. \\\n",
    "        --warmup_ratio 0.03 \\\n",
    "        --lr_scheduler_type \"cosine\" \\\n",
    "        --logging_steps 1 \\\n",
    "        --tf32 True \\\n",
    "        --model_max_length 2048 \\\n",
    "        --gradient_checkpointing True \\\n",
    "        --dataloader_num_workers 4 \\\n",
    "        --lazy_preprocess True \\\n",
    "        --report_to {'none' if test_run else report_to} \\\n",
    "        --output_dir {output_dir}\n",
    "    \"\"\"\n",
    "    \n",
    "    if test_run:\n",
    "        print('\\n'+' \\\\\\n\\t'.join([x.strip() for x in re.split(r'\\s{3,}', cmd)]))\n",
    "    \n",
    "    cmd = multiline_to_singleline(cmd)\n",
    "    cmds.append(cmd)\n",
    "    \n",
    "    \n",
    "    shell_scripts = shell_scripts_template.format(\n",
    "        profile='/fsx/wpq/.profile_local.sh',\n",
    "        conda_env='llava',\n",
    "        cwd=os.getcwd(),\n",
    "        cmd=cmd,\n",
    "        log_dir=log_dir,\n",
    "        save_dir=output_dir\n",
    "    )\n",
    "    \n",
    "    out = submit_job_slurm(\n",
    "        shell_scripts,\n",
    "        job_name=job_name,\n",
    "        partition='learnai4p',\n",
    "        nodes=nodes,\n",
    "        num_cpus=num_cpus,\n",
    "        cpu_mem=cpu_mem,\n",
    "        num_gpus=num_gpus,\n",
    "        log_path=os.path.join(log_dir, '%J.out'),\n",
    "        test_run=test_run,\n",
    "    )\n",
    "    \n",
    "    print(json.dumps(out, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1233839e-ca4d-4ec8-bf49-d2ccce11b9af",
   "metadata": {},
   "source": [
    "## Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32a4280e-30e3-4b62-a0ad-952a2d2fa839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloed https://evalai.s3.amazonaws.com/media/submission_files/submission_451709/7decbad8-5ee2-4c10-93ff-aad4ad0d7a5c.json\n",
      "\t->results/baselines/liuhaotian/llava-v1.5-7b/eval/vizwiz\n",
      "Downloed https://evalai.s3.amazonaws.com/media/submission_files/submission_450628/9bef3c4f-d7e2-4ff9-8d8a-84768881b20a.json\n",
      "\t->results/baselines/liuhaotian/llava-v1.5-7b/eval/vqav2\n",
      "Downloed https://evalai.s3.amazonaws.com/media/submission_files/submission_452449/1abc8d56-b08f-44ca-a6a8-88edb742d940.json\n",
      "\t->results/sft_1/lm=Llama-2-7b-hf_vis=clip-vit-large-patch14-336_mm=mlp2x_gelu/eval/vizwiz\n",
      "Downloed https://evalai.s3.amazonaws.com/media/submission_files/submission_452451/08618a88-3928-47f4-a352-673ac10dc1c5.json\n",
      "\t->results/sft_1/lm=Llama-2-7b-hf_vis=clip-vit-large-patch14-336_mm=mlp2x_gelu/eval/vqav2\n"
     ]
    }
   ],
   "source": [
    "from utils import download_eval_server_results\n",
    "download_eval_server_results('./eval_server_results.csv', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "37d5f326-23b8-4754-9069-ceadc8360cc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmds: #= 25\n",
      "[('mme', 'results/sft_1/lm=Llama-2-7b-hf_vis=clip-vit-large-patch14-336_mm=mlp2x_gelu'), ('vqav2', 'results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=mlp2x_gelu'), ('gqa', 'results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=mlp2x_gelu'), ('vizwiz', 'results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=mlp2x_gelu'), ('textvqa', 'results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=mlp2x_gelu'), ('scienceqa', 'results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=mlp2x_gelu'), ('pope', 'results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=mlp2x_gelu'), ('mme', 'results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=mlp2x_gelu'), ('mmbench', 'results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=mlp2x_gelu'), ('vqav2', 'results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=linear'), ('gqa', 'results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=linear'), ('vizwiz', 'results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=linear'), ('textvqa', 'results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=linear'), ('scienceqa', 'results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=linear'), ('pope', 'results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=linear'), ('mme', 'results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=linear'), ('mmbench', 'results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=linear'), ('vqav2', 'results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14_mm=mlp2x_gelu'), ('gqa', 'results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14_mm=mlp2x_gelu'), ('vizwiz', 'results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14_mm=mlp2x_gelu'), ('textvqa', 'results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14_mm=mlp2x_gelu'), ('scienceqa', 'results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14_mm=mlp2x_gelu'), ('pope', 'results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14_mm=mlp2x_gelu'), ('mme', 'results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14_mm=mlp2x_gelu'), ('mmbench', 'results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14_mm=mlp2x_gelu')] \n",
      "\n",
      "\n",
      "{\n",
      "    \"args\": \"sbatch /fsx/wpq/.sbatch/2024-06-14_06:57:48_665842b5-1b66-48df-bd30-31bb8cc8d4cd.sh\",\n",
      "    \"job_id\": 350432,\n",
      "    \"cmd\": \"bash scripts/v1_5/eval_mod/mme.sh results/sft_1/lm=Llama-2-7b-hf_vis=clip-vit-large-patch14-336_mm=mlp2x_gelu > results/sft_1/lm=Llama-2-7b-hf_vis=clip-vit-large-patch14-336_mm=mlp2x_gelu/eval/mme/bash_script_log.txt\"\n",
      "}\n",
      "{\n",
      "    \"args\": \"sbatch /fsx/wpq/.sbatch/2024-06-14_06:57:48_aa3fd359-e3dd-4097-a0a4-2588410b7cb3.sh\",\n",
      "    \"job_id\": 350433,\n",
      "    \"cmd\": \"bash scripts/v1_5/eval_mod/vqav2.sh results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=linear > results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=linear/eval/vqav2/bash_script_log.txt\"\n",
      "}\n",
      "{\n",
      "    \"args\": \"sbatch /fsx/wpq/.sbatch/2024-06-14_06:57:48_1c321b4e-81fa-4ed0-83e6-d6e79f2d9fd1.sh\",\n",
      "    \"job_id\": 350434,\n",
      "    \"cmd\": \"bash scripts/v1_5/eval_mod/gqa.sh results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=linear > results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=linear/eval/gqa/bash_script_log.txt\"\n",
      "}\n",
      "{\n",
      "    \"args\": \"sbatch /fsx/wpq/.sbatch/2024-06-14_06:57:48_9b9639df-6131-4aee-8efb-0a24cc8b570a.sh\",\n",
      "    \"job_id\": 350435,\n",
      "    \"cmd\": \"bash scripts/v1_5/eval_mod/vizwiz.sh results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=linear > results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=linear/eval/vizwiz/bash_script_log.txt\"\n",
      "}\n",
      "{\n",
      "    \"args\": \"sbatch /fsx/wpq/.sbatch/2024-06-14_06:57:48_990570df-d6dd-4f08-b24c-d83074c0c249.sh\",\n",
      "    \"job_id\": 350436,\n",
      "    \"cmd\": \"bash scripts/v1_5/eval_mod/textvqa.sh results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=linear > results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=linear/eval/textvqa/bash_script_log.txt\"\n",
      "}\n",
      "{\n",
      "    \"args\": \"sbatch /fsx/wpq/.sbatch/2024-06-14_06:57:48_c3607849-2e17-412c-a1ee-a31c34e3a431.sh\",\n",
      "    \"job_id\": 350437,\n",
      "    \"cmd\": \"bash scripts/v1_5/eval_mod/sqa.sh results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=linear > results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=linear/eval/scienceqa/bash_script_log.txt\"\n",
      "}\n",
      "{\n",
      "    \"args\": \"sbatch /fsx/wpq/.sbatch/2024-06-14_06:57:48_a0fe8e81-9aac-43e4-8e8a-1b79f0c4ba74.sh\",\n",
      "    \"job_id\": 350438,\n",
      "    \"cmd\": \"bash scripts/v1_5/eval_mod/pope.sh results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=linear > results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=linear/eval/pope/bash_script_log.txt\"\n",
      "}\n",
      "{\n",
      "    \"args\": \"sbatch /fsx/wpq/.sbatch/2024-06-14_06:57:48_a93fa3ff-564d-4888-a27e-5db4bb4b88a7.sh\",\n",
      "    \"job_id\": 350439,\n",
      "    \"cmd\": \"bash scripts/v1_5/eval_mod/mme.sh results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=linear > results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=linear/eval/mme/bash_script_log.txt\"\n",
      "}\n",
      "{\n",
      "    \"args\": \"sbatch /fsx/wpq/.sbatch/2024-06-14_06:57:48_503330af-af17-4dca-bed8-c3669b378789.sh\",\n",
      "    \"job_id\": 350440,\n",
      "    \"cmd\": \"bash scripts/v1_5/eval_mod/mmbench.sh results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=linear > results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=linear/eval/mmbench/bash_script_log.txt\"\n",
      "}\n",
      "{\n",
      "    \"args\": \"sbatch /fsx/wpq/.sbatch/2024-06-14_06:57:48_98bf3399-5819-4c07-bf97-38d230689847.sh\",\n",
      "    \"job_id\": 350441,\n",
      "    \"cmd\": \"bash scripts/v1_5/eval_mod/vqav2.sh results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=mlp2x_gelu > results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=mlp2x_gelu/eval/vqav2/bash_script_log.txt\"\n",
      "}\n",
      "{\n",
      "    \"args\": \"sbatch /fsx/wpq/.sbatch/2024-06-14_06:57:48_d37f8e0d-e168-430c-82eb-38e8e84fe181.sh\",\n",
      "    \"job_id\": 350442,\n",
      "    \"cmd\": \"bash scripts/v1_5/eval_mod/gqa.sh results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=mlp2x_gelu > results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=mlp2x_gelu/eval/gqa/bash_script_log.txt\"\n",
      "}\n",
      "{\n",
      "    \"args\": \"sbatch /fsx/wpq/.sbatch/2024-06-14_06:57:49_e72a8065-4234-4d2b-ad3f-59e0660dd51c.sh\",\n",
      "    \"job_id\": 350443,\n",
      "    \"cmd\": \"bash scripts/v1_5/eval_mod/vizwiz.sh results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=mlp2x_gelu > results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=mlp2x_gelu/eval/vizwiz/bash_script_log.txt\"\n",
      "}\n",
      "{\n",
      "    \"args\": \"sbatch /fsx/wpq/.sbatch/2024-06-14_06:57:49_fb02ff0f-abda-43b7-9a3b-5793a63d09ee.sh\",\n",
      "    \"job_id\": 350444,\n",
      "    \"cmd\": \"bash scripts/v1_5/eval_mod/textvqa.sh results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=mlp2x_gelu > results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=mlp2x_gelu/eval/textvqa/bash_script_log.txt\"\n",
      "}\n",
      "{\n",
      "    \"args\": \"sbatch /fsx/wpq/.sbatch/2024-06-14_06:57:49_0345105c-1ead-417e-bb43-52bbd63206d4.sh\",\n",
      "    \"job_id\": 350445,\n",
      "    \"cmd\": \"bash scripts/v1_5/eval_mod/sqa.sh results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=mlp2x_gelu > results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=mlp2x_gelu/eval/scienceqa/bash_script_log.txt\"\n",
      "}\n",
      "{\n",
      "    \"args\": \"sbatch /fsx/wpq/.sbatch/2024-06-14_06:57:49_319aa2c4-b771-49fb-b72a-fa3519840626.sh\",\n",
      "    \"job_id\": 350446,\n",
      "    \"cmd\": \"bash scripts/v1_5/eval_mod/pope.sh results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=mlp2x_gelu > results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=mlp2x_gelu/eval/pope/bash_script_log.txt\"\n",
      "}\n",
      "{\n",
      "    \"args\": \"sbatch /fsx/wpq/.sbatch/2024-06-14_06:57:49_8b054920-7267-41a2-a276-336ad406faa1.sh\",\n",
      "    \"job_id\": 350447,\n",
      "    \"cmd\": \"bash scripts/v1_5/eval_mod/mme.sh results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=mlp2x_gelu > results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=mlp2x_gelu/eval/mme/bash_script_log.txt\"\n",
      "}\n",
      "{\n",
      "    \"args\": \"sbatch /fsx/wpq/.sbatch/2024-06-14_06:57:49_ea6f52c4-3890-4add-87a3-a93044d03129.sh\",\n",
      "    \"job_id\": 350448,\n",
      "    \"cmd\": \"bash scripts/v1_5/eval_mod/mmbench.sh results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=mlp2x_gelu > results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14-336_mm=mlp2x_gelu/eval/mmbench/bash_script_log.txt\"\n",
      "}\n",
      "{\n",
      "    \"args\": \"sbatch /fsx/wpq/.sbatch/2024-06-14_06:57:49_4f855490-7f8a-404c-9003-83e3655a9a4d.sh\",\n",
      "    \"job_id\": 350449,\n",
      "    \"cmd\": \"bash scripts/v1_5/eval_mod/vqav2.sh results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14_mm=mlp2x_gelu > results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14_mm=mlp2x_gelu/eval/vqav2/bash_script_log.txt\"\n",
      "}\n",
      "{\n",
      "    \"args\": \"sbatch /fsx/wpq/.sbatch/2024-06-14_06:57:49_a30d9aa0-50ee-4b39-b77b-d6344ccf912b.sh\",\n",
      "    \"job_id\": 350450,\n",
      "    \"cmd\": \"bash scripts/v1_5/eval_mod/gqa.sh results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14_mm=mlp2x_gelu > results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14_mm=mlp2x_gelu/eval/gqa/bash_script_log.txt\"\n",
      "}\n",
      "{\n",
      "    \"args\": \"sbatch /fsx/wpq/.sbatch/2024-06-14_06:57:49_93f91757-8290-4b18-a8ef-a353307f962e.sh\",\n",
      "    \"job_id\": 350451,\n",
      "    \"cmd\": \"bash scripts/v1_5/eval_mod/vizwiz.sh results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14_mm=mlp2x_gelu > results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14_mm=mlp2x_gelu/eval/vizwiz/bash_script_log.txt\"\n",
      "}\n",
      "{\n",
      "    \"args\": \"sbatch /fsx/wpq/.sbatch/2024-06-14_06:57:49_6dab43e4-bfd8-48d8-8abc-79f434fd4a0b.sh\",\n",
      "    \"job_id\": 350452,\n",
      "    \"cmd\": \"bash scripts/v1_5/eval_mod/textvqa.sh results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14_mm=mlp2x_gelu > results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14_mm=mlp2x_gelu/eval/textvqa/bash_script_log.txt\"\n",
      "}\n",
      "{\n",
      "    \"args\": \"sbatch /fsx/wpq/.sbatch/2024-06-14_06:57:49_250ec383-1ee4-43f0-b399-f7a967ad65bd.sh\",\n",
      "    \"job_id\": 350453,\n",
      "    \"cmd\": \"bash scripts/v1_5/eval_mod/sqa.sh results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14_mm=mlp2x_gelu > results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14_mm=mlp2x_gelu/eval/scienceqa/bash_script_log.txt\"\n",
      "}\n",
      "{\n",
      "    \"args\": \"sbatch /fsx/wpq/.sbatch/2024-06-14_06:57:49_7b62e2e4-425c-4861-862c-7d49ef979a12.sh\",\n",
      "    \"job_id\": 350454,\n",
      "    \"cmd\": \"bash scripts/v1_5/eval_mod/pope.sh results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14_mm=mlp2x_gelu > results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14_mm=mlp2x_gelu/eval/pope/bash_script_log.txt\"\n",
      "}\n",
      "{\n",
      "    \"args\": \"sbatch /fsx/wpq/.sbatch/2024-06-14_06:57:49_0d292078-7f65-40c4-9fdf-45b33247ee3e.sh\",\n",
      "    \"job_id\": 350455,\n",
      "    \"cmd\": \"bash scripts/v1_5/eval_mod/mme.sh results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14_mm=mlp2x_gelu > results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14_mm=mlp2x_gelu/eval/mme/bash_script_log.txt\"\n",
      "}\n",
      "{\n",
      "    \"args\": \"sbatch /fsx/wpq/.sbatch/2024-06-14_06:57:49_be543541-71c2-40bd-a787-11597538f46c.sh\",\n",
      "    \"job_id\": 350456,\n",
      "    \"cmd\": \"bash scripts/v1_5/eval_mod/mmbench.sh results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14_mm=mlp2x_gelu > results/sft_1/lm=vicuna-7b-v1.5_vis=clip-vit-large-patch14_mm=mlp2x_gelu/eval/mmbench/bash_script_log.txt\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from rosemary.submit import submit_job_slurm\n",
    "nodes = 1; num_gpus = 8; cpu_mem = 1000; num_cpus = 96\n",
    "\n",
    "eval_script_dir = 'scripts/v1_5/eval_mod'\n",
    "eval_rest = True\n",
    "subdir_path_list = []\n",
    "subdir_filter_fn = lambda x: True\n",
    "\n",
    "\n",
    "task_names_vqa = ['vqav2', 'gqa', 'vizwiz', 'textvqa', 'scienceqa']\n",
    "task_names_sft = ['pope', 'mme', 'mmbench', 'seed', 'llavabench', 'mmvet']\n",
    "task_names_all = task_names_vqa + task_names_sft\n",
    "task_names_routine = ['vqav2', 'gqa', 'vizwiz', 'textvqa', 'scienceqa', 'pope', 'mme', 'mmbench',]\n",
    "task_names_llm_evaluator = ['llavabench', 'mmvet']\n",
    "\n",
    "######\n",
    "\n",
    "# ## baselines\n",
    "# subdir_path_list = [\n",
    "#     'results/baselines/liuhaotian/llava-v1.5-7b',\n",
    "# ]\n",
    "# task_names = ['llavabench']\n",
    "# eval_rest = False\n",
    "\n",
    "# sft_1\n",
    "exp_dirs = ['results/sft_1']\n",
    "task_names = task_names_routine\n",
    "\n",
    "\n",
    "\n",
    "######\n",
    "\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "\n",
    "if len(subdir_path_list)==0:\n",
    "    subdir_path_list = []\n",
    "    for exp_dir in exp_dirs:\n",
    "        subdirs = list(os.listdir(exp_dir))\n",
    "        subdirs = filter(subdir_filter_fn, subdirs)\n",
    "        for subdir in subdirs:\n",
    "            subdir_path = os.path.join(exp_dir, subdir)\n",
    "            if not os.path.isfile(os.path.join(subdir_path, 'config.json')): # skip runs not yet finished\n",
    "                continue\n",
    "            subdir_path_list.append(subdir_path)\n",
    "\n",
    "@dataclass\n",
    "class TaskConfig:\n",
    "    task_finish_proof: str\n",
    "    num_gpus: int\n",
    "    bash_script_name: str\n",
    "\n",
    "task_configs = {\n",
    "    'vqav2': TaskConfig('*/answers_upload.json', 8, 'vqav2'),\n",
    "    'gqa': TaskConfig('*/*_predictions.json', 8, 'gqa'),\n",
    "    'vizwiz': TaskConfig('answers_upload.json', 1, 'vizwiz'),\n",
    "    'textvqa': TaskConfig('answers.jsonl', 1, 'textvqa'),\n",
    "    'scienceqa': TaskConfig('results.jsonl', 1, 'sqa'),\n",
    "    'pope': TaskConfig('answers.jsonl', 1, 'pope'),\n",
    "    'mme': TaskConfig('results', 1, 'mme'),\n",
    "    'mmbench': TaskConfig('*.xlsx', 1, 'mmbench'),\n",
    "    'mmvet': TaskConfig('results_*.csv', 1, 'mmvet'),\n",
    "    'seed': TaskConfig('answers_upload.jsonl', 8, 'seed'),\n",
    "    'llavabench': TaskConfig('reviews.jsonl', 1, 'llavabench'),\n",
    "}\n",
    "\n",
    "if eval_rest:\n",
    "    task_name_and_model = []\n",
    "    for subdir_path in subdir_path_list:\n",
    "        for task_name in task_names:\n",
    "            if not glob.glob(os.path.join(subdir_path, 'eval', task_name, task_configs[task_name].task_finish_proof)):\n",
    "                task_name_and_model.append((task_name, subdir_path))\n",
    "else:\n",
    "    task_name_and_model = list(itertools.product(task_names, subdir_path_list))\n",
    "    \n",
    "print('cmds: #=', len(list(task_name_and_model)))\n",
    "print(list(task_name_and_model), '\\n\\n')\n",
    "\n",
    "\n",
    "dfo = pd.DataFrame(task_name_and_model, columns=['task_name', 'model_name_or_path'])\n",
    "model_and_task_list = dfo.groupby('model_name_or_path')['task_name'].agg(list).to_dict()\n",
    "\n",
    "cmds = []\n",
    "for model_name_or_path, task_name_list in model_and_task_list.items():\n",
    "    model_name_or_path = model_name_or_path.rstrip('/')\n",
    "    for i, task_name in enumerate(task_name_list):\n",
    "        task_config = task_configs[task_name]\n",
    "        job_name = f'eval.{task_name}'\n",
    "        save_dir = f'{model_name_or_path}/eval/{task_name}'\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        if task_name.startswith(tuple(task_configs.keys())):\n",
    "            cmd = f\"bash {eval_script_dir}/{task_config.bash_script_name}.sh {model_name_or_path} > {os.path.join(save_dir,'bash_script_log.txt')}\"\n",
    "        else:\n",
    "            raise ValueError(f'{task_name} not supported.')\n",
    "\n",
    "        num_gpus = task_config.num_gpus            \n",
    "        cmd = multiline_to_singleline(cmd)\n",
    "        cmds.append(cmd)\n",
    "        \n",
    "        shell_scripts = shell_scripts_template.format(\n",
    "            profile='/fsx/wpq/.profile_local.sh',\n",
    "            conda_env='llava',\n",
    "            cwd=os.getcwd(),\n",
    "            cmd=cmd,\n",
    "            log_dir=log_dir,\n",
    "            save_dir=save_dir\n",
    "        )\n",
    "        out = submit_job_slurm(\n",
    "            shell_scripts, \n",
    "            job_name=job_name,\n",
    "            partition='learnai4p',\n",
    "            nodes=nodes,\n",
    "            num_cpus=num_cpus,\n",
    "            cpu_mem=cpu_mem,\n",
    "            num_gpus=num_gpus,\n",
    "        log_path=os.path.join(log_dir, '%J.out'),\n",
    "            test_run=test_run,\n",
    "        )\n",
    "        for x in out:\n",
    "            x.update({'cmd': cmd})\n",
    "\n",
    "        print(json.dumps(out[0], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524ff30a-41ae-4065-8117-3c79573eaad0",
   "metadata": {},
   "source": [
    "## Eval Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "149ebfe0-e1b4-4a90-b1ff-210a7701f5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f2dc4 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_f2dc4_row0_col0, #T_f2dc4_row1_col0 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_f2dc4_row0_col1, #T_f2dc4_row0_col2, #T_f2dc4_row0_col3, #T_f2dc4_row0_col4, #T_f2dc4_row0_col6, #T_f2dc4_row1_col4, #T_f2dc4_row1_col5, #T_f2dc4_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2dc4_row0_col5, #T_f2dc4_row0_col7, #T_f2dc4_row1_col1, #T_f2dc4_row1_col2, #T_f2dc4_row1_col3, #T_f2dc4_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f2dc4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f2dc4_level0_col0\" class=\"col_heading level0 col0\" >Method</th>\n",
       "      <th id=\"T_f2dc4_level0_col1\" class=\"col_heading level0 col1\" >VQAv2/acc</th>\n",
       "      <th id=\"T_f2dc4_level0_col2\" class=\"col_heading level0 col2\" >GQA/acc</th>\n",
       "      <th id=\"T_f2dc4_level0_col3\" class=\"col_heading level0 col3\" >VizWiz/acc</th>\n",
       "      <th id=\"T_f2dc4_level0_col4\" class=\"col_heading level0 col4\" >ScienceQA/acc</th>\n",
       "      <th id=\"T_f2dc4_level0_col5\" class=\"col_heading level0 col5\" >TextVQA/acc</th>\n",
       "      <th id=\"T_f2dc4_level0_col6\" class=\"col_heading level0 col6\" >POPE/F1-score</th>\n",
       "      <th id=\"T_f2dc4_level0_col7\" class=\"col_heading level0 col7\" >MME/perception</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f2dc4_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f2dc4_row0_col0\" class=\"data row0 col0\" >LLaVA-v1.5-7b</td>\n",
       "      <td id=\"T_f2dc4_row0_col1\" class=\"data row0 col1\" >78.5</td>\n",
       "      <td id=\"T_f2dc4_row0_col2\" class=\"data row0 col2\" >62.0</td>\n",
       "      <td id=\"T_f2dc4_row0_col3\" class=\"data row0 col3\" >50.0</td>\n",
       "      <td id=\"T_f2dc4_row0_col4\" class=\"data row0 col4\" >72.7</td>\n",
       "      <td id=\"T_f2dc4_row0_col5\" class=\"data row0 col5\" >58.2</td>\n",
       "      <td id=\"T_f2dc4_row0_col6\" class=\"data row0 col6\" >85.9</td>\n",
       "      <td id=\"T_f2dc4_row0_col7\" class=\"data row0 col7\" >1506.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2dc4_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f2dc4_row1_col0\" class=\"data row1 col0\" >lm=Llama-2-7b-hf_vis=clip-vit-large-patch14-336_mm=mlp2x_gelu</td>\n",
       "      <td id=\"T_f2dc4_row1_col1\" class=\"data row1 col1\" >79.1</td>\n",
       "      <td id=\"T_f2dc4_row1_col2\" class=\"data row1 col2\" >62.7</td>\n",
       "      <td id=\"T_f2dc4_row1_col3\" class=\"data row1 col3\" >54.3</td>\n",
       "      <td id=\"T_f2dc4_row1_col4\" class=\"data row1 col4\" >72.7</td>\n",
       "      <td id=\"T_f2dc4_row1_col5\" class=\"data row1 col5\" >57.6</td>\n",
       "      <td id=\"T_f2dc4_row1_col6\" class=\"data row1 col6\" >86.3</td>\n",
       "      <td id=\"T_f2dc4_row1_col7\" class=\"data row1 col7\" >1474.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f28a163f700>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import TaskResult, ModelResult, get_eval_results\n",
    "\n",
    "save_dirs = []\n",
    "save_dirs += [('LLaVA-v1.5-7b', 'results/baselines/liuhaotian/llava-v1.5-7b')]\n",
    "exp_dir = 'results/sft_1'\n",
    "save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "\n",
    "metrics_names = [\n",
    "    'VQAv2/acc', 'GQA/acc', 'VizWiz/acc', 'ScienceQA/acc', 'TextVQA/acc', \n",
    "    'POPE/F1-score', 'MME/perception', # 'MMBench/acc', 'LLaVA/all', 'MM-Vet/score'\n",
    "]\n",
    "\n",
    "df = get_eval_results(save_dirs, metrics_names)\n",
    "\n",
    "display(df\n",
    "    .style\n",
    "    # .applymap(lambda x: f'max-width: 60ch;', subset=['sort_by_name'])\n",
    "    .set_table_styles([{'selector': 'td', 'props': [('white-space', 'pre-wrap'), ('word-wrap', 'break-word')]}])\n",
    "    .set_properties(**{'text-align': 'left'})\n",
    "    .background_gradient(cmap ='coolwarm')\n",
    "    .format(precision=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ce96c493-2d06-444b-a4ce-8f041b27cfea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | Method                                                        |   VQAv2/acc |   GQA/acc |   VizWiz/acc |   ScienceQA/acc |   TextVQA/acc |   POPE/F1-score |   MME/perception |\n",
      "|---:|:--------------------------------------------------------------|------------:|----------:|-------------:|----------------:|--------------:|----------------:|-----------------:|\n",
      "|  0 | LLaVA-v1.5-7b                                                 |        78.5 |      62   |         50   |            72.7 |          58.2 |            85.9 |           1506.8 |\n",
      "|  1 | lm=Llama-2-7b-hf_vis=clip-vit-large-patch14-336_mm=mlp2x_gelu |        79.1 |      62.7 |         54.3 |            72.7 |          57.6 |            86.3 |           1474.1 |\n"
     ]
    }
   ],
   "source": [
    "print(df.round(1).to_markdown())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e933e7e-0609-4370-8b20-658f8d9f5c77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:llava]",
   "language": "python",
   "name": "conda-env-llava-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
